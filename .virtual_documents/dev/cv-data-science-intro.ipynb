import os
import cv2
import glob
import numpy as np
import matplotlib.pyplot as plt
import xml.etree.ElementTree as ET
from gdrive_handler import GD_Handler

gd_handler = GD_Handler() # only need one for the whole notebook so initialize here

ANNOTATION_COLOR=(0,255,0)    # this value is a const throughout the notebook and will not change so we define it here also
ANNOTATION_THICKNESS=2


gd_handler.downloadBatch('Yogi')
gd_handler.downloadBatch('Batch20') # download the Batch20 data


yogi = cv2.imread('../data/yogimus.jpg')
cv2.imshow('sample', yogi)
cv2.waitKey(0)
cv2.destroyAllWindows()


filenames = glob.glob('../data/*.jpg')
images = [cv2.imread(file) for file in filenames]
print(f'Number of Images {len(images)}')
cv2.imshow('image0', images[0])
cv2.waitKey(0)
cv2.destroyAllWindows()


def buffshow(title, image, wait=0):
    cv2.imshow(title, image)
    cv2.waitKey(wait)
    cv2.destroyAllWindows()

buffshow('image0', images[0])


filenames = glob.glob('../data/*.xml')
labels = [ET.parse(file) for file in filenames]
print(f'Number of Labels {len(labels)}')
print(labels[0])


root = labels[0].getroot()
print(root.tag, root.attrib)

for i in range(len(root)):
    print(root[i].tag, root[i].attrib, root[i].text)
    for j in range(len(root[i])):
        print(f'\t', root[i][j].tag, root[i][j].attrib, root[i][j].text)
        for k in range(len(root[i][j])):
            print(f'\t\t', root[i][j][k].tag, root[i][j][k].attrib, root[i][j][k].text)


def get_bounding_from_label(label):
    bounds = []
    boundingboxes = label.findall('object')
    for boundary in boundingboxes:
        bound = boundary.find('bndbox')
        xmin = int(bound.find('xmin').text)
        ymin = int(bound.find('ymin').text)
        xmax = int(bound.find('xmax').text)
        ymax = int(bound.find('ymax').text)
        bounds.append([(xmin, ymin), (xmax, ymax)])
    return bounds
        
bounds = get_bounding_from_label(labels[0])
print(bounds)    


def display_annotated_raw(data_point):
    image, label = data_point
    bounds = get_bounding_from_label(label)
    for bound in bounds:
        image = cv2.rectangle(image, bound[0], bound[1], ANNOTATION_COLOR, ANNOTATION_THICKNESS)
        
    buffshow('annotated', image)

for i in range(0,5): # try adjusting 0 and 5
    display_annotated_raw((images[i], labels[i]))


def load_images(path):
    filenames = glob.glob(path)
    return [(file.split('/')[-1], cv2.imread(file)) for file in filenames] # by saving the image with its filename we can properly match it to the data

def load_labels(path):
    filenames = glob.glob(path)
    return [ET.parse(file) for file in filenames]

def get_image_file_from_label(label):
    return label.find('filename').text
    
def load_data(path='../data'):
    images = load_images(os.path.join(path, '*.jpg'))
    labels = load_labels(os.path.join(path, '*.xml'))
    if len(images) - len(labels):
        print(f'mismatched: images {len(images)} != labels {len(labels)}')
        
    data = []
    for label in labels:
        file = get_image_file_from_label(label)
        for image in images:
            if image[0] == file:
                data.append((image[1], get_bounding_from_label(label)))
                
    return data

def display_annotated(data):
    image, bounds = data
    for bound in bounds:
        image = cv2.rectangle(image, bound[0], bound[1], ANNOTATION_COLOR, ANNOTATION_THICKNESS)
        
    buffshow('annotated', image)
    

data = load_data()
print(f'Number of data points: {len(data)}')
display_annotated(data[0])


def parse_data(data):
    box_size = []
    n_targets = []
    center_x = []
    center_y = []
    for i,(image, label) in enumerate(data):
            n = 0
            for (x1,y1),(x2,y2) in label:
                n += 1
                h = np.abs(y2 - y1)
                w = np.abs(x2 - x1)
                box_size.append(w * h)
                center_x.append(x1 + int(w/2))
                center_y.append(y1 + int(h/2))
            n_targets.append(n)
            
    return box_size, n_targets, center_x, center_y

def analyze_data(data):
    s, n, cx, cy = parse_data(data)
    fig, axes = plt.subplots(1, 3, figsize=(15, 8), tight_layout=True)
    axes[0].hist(n, bins=10)
    axes[0].set_title('Number of targets')
    axes[1].hist(s, bins=50)
    axes[1].set_title('Box Size')
    axes[2].scatter(cx, cy)
    axes[2].set_title('Center points') # note that opencv images are bottom=640 and top=0, they will appear upside down here
    axes[2].set_ylim(bottom=0, top=360)
    axes[2].set_xlim(left=0, right=640)
    plt.show()
    
analyze_data(data)


new_label = []
x1 = None
x2 = None
y1 = None
y2 = None

# this labeler is set up to make xmin, xmax : mouse left click down, mouse left click up
# and then make ymin max in the same way, Once all four variables are filled it will save
# them in new_label. (click the xmin and drag to the xmax then release, repeat for y)
# when you mark the new label press q to close the image (do not click the red x).

def click_event(event, x, y, flags, param):
    global x1, x2, y1, y2, new_label
    # on press mark position
    if event == cv2.EVENT_LBUTTONDOWN:
        print('mouse down')
        # Take turns between reading width and height
        if x1 is None:
            x1 = x
        else:
            y1 = y

    elif event == cv2.EVENT_LBUTTONUP:
        print('mouse up')
        if x2 is None:
            x2 = x
        else:
            y2 = y
            
    if not y2 is None:
        print('recorded')
        new_label.append([(min(x1, x2), min(y1, y2)), (max(x1, x2), max(y1,y2))])
        x1 = None
        x2 = None
        y1 = None
        y2 = None
        
cv2.namedWindow("image")
cv2.setMouseCallback("image", click_event)

sample = data[-1]

buffshow("image", sample[0])
display_annotated((sample[0], new_label))


image1 = data[-1][0]

red_lower = (0,0,100) #bgr for red, lower boundary
red_upper = (80,80,255) #bgr for red, upper boundary
blue_lower = (100,0,0) #bgr for blue, lower boundary
blue_upper = (255,80,80) #bgr for blue, upper boundary

red_mask = cv2.inRange(image1, red_lower, red_upper)
blue_mask = cv2.inRange(image1, blue_lower, blue_upper)

red_output = cv2.bitwise_and(image1, image1, mask=red_mask)
blue_output = cv2.bitwise_and(image1, image1, mask=blue_mask)

buffshow('red-detect', red_output)
buffshow('redmask', red_mask)
buffshow('blue-detect', blue_output)



